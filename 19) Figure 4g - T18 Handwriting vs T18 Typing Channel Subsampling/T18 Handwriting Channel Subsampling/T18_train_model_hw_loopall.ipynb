{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training datasets for decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../../')\n",
    "import lm_decoder\n",
    "from utils.lmutils import cer_with_lm_decoder, build_lm_decoder\n",
    "\n",
    "lmDir = '../../LanguageModels/Typing5gramPunc'\n",
    "\n",
    "ngramDecoder = build_lm_decoder(\n",
    "    lmDir,\n",
    "    max_active=7000,\n",
    "    min_active=200,\n",
    "    beam=17,\n",
    "    lattice_beam=8,\n",
    "    acoustic_scale=0.23, #lower means weight LM more highly\n",
    "    ctc_blank_skip_threshold=1.0,\n",
    "    length_penalty=0.0,\n",
    "    nbest=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../../')\n",
    "import utils.mat_to_tfrecord_handwriting\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from T18_SessionArgs import get_session_info\n",
    "\n",
    "\n",
    "sessions = [\n",
    "    't18.2025.04.01',\n",
    "     ]\n",
    "\n",
    "participant = 't18'\n",
    "bin_compression_factor = 2\n",
    "channels_to_exclude = list(range(0,0))\n",
    "channels_to_zero = list(range(0,0)) #[] # leave empty to not zero anything\n",
    "\n",
    "for session in sessions:\n",
    "    trials_to_remove, block_nums, num_test_trials = get_session_info(session)\n",
    "    session_path = str(Path('../../Data', participant, session, 'Handwriting'))\n",
    "    tfdata_path = str(Path(session_path, 'tfdata_20ms'))\n",
    "\n",
    "    print(f'Sesison path: {session_path}')\n",
    "    print(f'tfdata path: {session_path}')\n",
    "    print('\\n')\n",
    "\n",
    "    args = {\n",
    "        'session_mat_path': session_path,\n",
    "        'block_nums': block_nums,\n",
    "        'num_test_trials': num_test_trials,\n",
    "        'trials_to_remove': trials_to_remove,\n",
    "        'channels_to_exclude': channels_to_exclude,\n",
    "        'channels_to_zero': channels_to_zero,\n",
    "        'include_thresh_crossings': True,\n",
    "        'include_spike_power': True,\n",
    "        'spike_pow_max': 50000,\n",
    "        'z_score_data': True,\n",
    "        'global_std': True,\n",
    "        'bin_compression_factor': bin_compression_factor,\n",
    "        'save_path': tfdata_path,\n",
    "    }\n",
    "\n",
    "    utils.mat_to_tfrecord_handwriting.main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the decoder. Remember to Restart the notebook first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gc\n",
    "sys.path.append('../../')\n",
    "import numpy as np\n",
    "num_sampled_electrodes = [10,20,30,40,60,80,100,120,140,160,180,200,220,240,260,280,300,320,340,360,380]\n",
    "random_seeds = np.arange(40)\n",
    "import importlib\n",
    "import tensorflow as tf\n",
    "from omegaconf import OmegaConf\n",
    "for num_electrodes in num_sampled_electrodes:\n",
    "    for seed in random_seeds:\n",
    "        import sys\n",
    "        import gc\n",
    "        sys.path.append('../../')\n",
    "        import numpy as np\n",
    "        import importlib\n",
    "        from utils.lmutils import cer_with_lm_decoder\n",
    "        from omegaconf import OmegaConf\n",
    "        args = OmegaConf.load('T18_trainArgs.yaml')\n",
    "        from utils.brainToText_trainDecoder_subsampling import brainToText_decoder\n",
    "        args['dataset']['nInputFeatures'] = num_electrodes*2\n",
    "        args['model']['inputLayerSize'] = num_electrodes*2\n",
    "        args['model']['inputNetwork']['inputLayerSizes'] = [num_electrodes*2]\n",
    "        sampled_electrodes = np.random.choice(np.arange(384), num_electrodes, replace=False)\n",
    "        args['dataset']['sampledElectrodes'] = sampled_electrodes.tolist()\n",
    "        args['loadDir'] = 'null'\n",
    "        decoder = brainToText_decoder(args)\n",
    "        infOut, stats = decoder.train()\n",
    "        args['loadDir'] = 'HandwritingModel'\n",
    "        decoder = None\n",
    "        gc.collect()\n",
    "        decoder = brainToText_decoder(args)\n",
    "        out, out_by_day = decoder.inference()\n",
    "        decoder_out = cer_with_lm_decoder(ngramDecoder, out, blankPenalty=0.2, rescore=False)\n",
    "        print('Num Eelectrodes, Seed: ', str(num_electrodes), seed)\n",
    "        print('Val CER post LM: ', decoder_out['cer'])\n",
    "        print('Val WER post LM: ',decoder_out['wer'])\n",
    "        for d,t in zip(decoder_out['true_transcripts'], decoder_out['decoded_transcripts']):\n",
    "            print('True :' ,d, ', Decoded: ', t)\n",
    "        np.save('T18TrainHandwriting-Electrodes-' + str(num_electrodes) + '-Seed-'+str(seed)+'-WERPostLM.npy',decoder_out['all_wer'])\n",
    "        del decoder\n",
    "        decoder = None\n",
    "        gc.collect()\n",
    "        tf.keras.backend.clear_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
