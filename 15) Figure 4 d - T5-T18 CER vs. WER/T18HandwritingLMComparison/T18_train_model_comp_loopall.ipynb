{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training datasets for decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../../')\n",
    "import lm_decoder\n",
    "from utils.lmutils import cer_with_lm_decoder, build_lm_decoder\n",
    "\n",
    "lmDir = '../../LanguageModels/Typing5gramPunc'\n",
    "\n",
    "ngramDecoder = build_lm_decoder(\n",
    "    lmDir,\n",
    "    max_active=7000,\n",
    "    min_active=200,\n",
    "    beam=17,\n",
    "    lattice_beam=8,\n",
    "    acoustic_scale=0.23, #lower means weight LM more highly\n",
    "    ctc_blank_skip_threshold=1.0,\n",
    "    length_penalty=0.0,\n",
    "    nbest=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../../')\n",
    "import utils.mat_to_tfrecord_handwriting\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from T18_SessionArgs_comp import get_session_info\n",
    "\n",
    "\n",
    "sessions = [\n",
    "    't18.2025.04.01_CERWER',\n",
    "     ]\n",
    "\n",
    "participant = 't18'\n",
    "bin_compression_factor = 2\n",
    "channels_to_exclude = list(range(0,0))\n",
    "channels_to_zero = list(range(0,0)) #[] # leave empty to not zero anything\n",
    "\n",
    "for session in sessions:\n",
    "    trials_to_remove, block_nums, num_test_trials = get_session_info(session)\n",
    "    session_path = str(Path('../../Data', participant, session, 'Handwriting'))\n",
    "    tfdata_path = str(Path(session_path, 'tfdata_20ms'))\n",
    "\n",
    "    print(f'Sesison path: {session_path}')\n",
    "    print(f'tfdata path: {session_path}')\n",
    "    print('\\n')\n",
    "\n",
    "    args = {\n",
    "        'session_mat_path': session_path,\n",
    "        'block_nums': block_nums,\n",
    "        'num_test_trials': num_test_trials,\n",
    "        'trials_to_remove': trials_to_remove,\n",
    "        'channels_to_exclude': channels_to_exclude,\n",
    "        'channels_to_zero': channels_to_zero,\n",
    "        'include_thresh_crossings': True,\n",
    "        'include_spike_power': True,\n",
    "        'spike_pow_max': 50000,\n",
    "        'z_score_data': True,\n",
    "        'global_std': True,\n",
    "        'bin_compression_factor': bin_compression_factor,\n",
    "        'save_path': tfdata_path,\n",
    "    }\n",
    "\n",
    "    utils.mat_to_tfrecord_handwriting.main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the decoder. Remember to Restart the notebook first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_CERs = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7]\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import gc\n",
    "sys.path.append('../../')\n",
    "import numpy as np\n",
    "import importlib\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "for target_cer in all_CERs:\n",
    "    import sys\n",
    "    import gc\n",
    "    sys.path.append('../../')\n",
    "    import numpy as np\n",
    "    import importlib\n",
    "    from utils.lmutils import cer_with_lm_decoder\n",
    "    from omegaconf import OmegaConf\n",
    "    args = OmegaConf.load('T18_trainArgs_comp.yaml')\n",
    "    from utils.brainToText_trainDecoder import brainToText_decoder\n",
    "    args['outputDir'] = 'T18_LM_comparison_models_HW/' + str(target_cer) + 'CER'\n",
    "    args['EndCER'] = target_cer\n",
    "    decoder = brainToText_decoder(args)\n",
    "    infOut, stats = decoder.train()\n",
    "    out, out_by_day = decoder.inference()\n",
    "    decoder_out = cer_with_lm_decoder(ngramDecoder, out, blankPenalty=1, rescore=False)\n",
    "    print('Target CER: ', str(target_cer))\n",
    "    print('Val CER post LM: ', decoder_out['cer'])\n",
    "    print('Val WER post LM: ',decoder_out['wer'])\n",
    "    for d,t in zip(decoder_out['true_transcripts'], decoder_out['decoded_transcripts']):\n",
    "        print('True :' ,d, ', Decoded: ', t)\n",
    "    np.save('T18HWTrain-' + str(target_cer) + '-WERPostLM.npy',decoder_out['all_wer'])\n",
    "    decoder = None\n",
    "    gc.collect()\n",
    "    tf.keras.backend.clear_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
